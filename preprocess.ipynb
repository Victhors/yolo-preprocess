{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # para conexão com o windows e criacao de pastas\n",
    "import shutil # para alterações em pastas\n",
    "from glob import Path # transformar em lista\n",
    "from pathlib import Path\n",
    "from collections import Counter \n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "def preprocess_dataset(imgs_path=None, txts_path=None,videos_path=None, classes_txt=None, yolo_ds_path=None,val_size=0.2, img_filetypes=(\"jpeg\", \"jpg\", \"png\", \"tif\", \"bmp\"), frame_rate=1, \n",
    "                       random_state=42):\n",
    "    \"\"\"\n",
    "    Pré Processamento do Dataset para Yolov9m, esssa função vai:\n",
    "    1. Carregar arquivos de images e/ou videos e extrair os frames de cada video\n",
    "    2. Garante que cada imagem ou cada frame extraido tenha seu respectivo txt\n",
    "    3. Separa o database entre treino e validação\n",
    "    4. Prepara a estrutura de dataset para o Yolov9m\n",
    "    5. Cria um dataset yaml file que precisará para o treino do Yolov9\n",
    "    \n",
    "    Parametros (Foi necessário colocar none em todos como padrão porque as operações em que usaremos essa função podem ser só imagens ou só videos):\n",
    "    - IMGS_PATH (Path ou String): path para o diretório que contém as imagens.\n",
    "    - TXTS_PATH (Path ou String): path para o diretório contendo txt\n",
    "    - VIDEOS_PATH (Path ou String): path para o diretório contendo os videos\n",
    "    - CLASSES_TXT (Path ou String): path para o arquivo classes_txt\n",
    "    - YOLO_DS_PATH (path ou string): path onde o dataset pronto do yolo será salvo\n",
    "    - val_size (Float): Porcentagem de imagens que serão usadas na validação. Default como 0.2 (20%)\n",
    "    - img_filetypes (tuple): Tupla de imagens contendo todas as extensões que serão buscadas\n",
    "    - frame_rate (int): Frame rate para extrair os frames dos videos (em frames por segundo)\n",
    "    - random_state (int): Semente para reprodução\n",
    "    \n",
    "    Retorna:\n",
    "    - Nada\n",
    "    \"\"\"\n",
    "    \n",
    "    if not imgs_path and not videos_path:\n",
    "        raise ValueError(\"Dê pelo menos uma pasta de video ou pelo menos uma pasta de imagens\")\n",
    "    \n",
    "    # Processamento inicial\n",
    "    \n",
    "    imgs = []\n",
    "\n",
    "    # 1. Carrega Imagens\n",
    "    if imgs_path:\n",
    "        imgs_path = Path(imgs_path) # nao se esqueça de colocar o r\n",
    "        for filetype in img_filetypes:\n",
    "            imgs.extend(imgs_path.glob(f\"*.{filetype}\"))\n",
    "    \n",
    "    # 2. Extrai frames dos videos\n",
    "    if videos_path:\n",
    "        videos_path = Path(videos_path)\n",
    "        videos_files = list(videos_path.glob(\"*.mp4\"))\n",
    "        \n",
    "        def extract_frames(video_file, output_dir, frame_rate=1):\n",
    "            \"\"\"Extrai os frames de cada video baseado no frame_rate especificado\"\"\"\n",
    "            video_name = video_file.stem\n",
    "            cap = cv2.VideoCapture(str(video_file))\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS)) # fps do video\n",
    "            count = 0\n",
    "            frame_count = 0\n",
    "            \n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                if count % (fps // frame_rate) == 0: # Captura um frame de um especifico frame rate\n",
    "                    frame_name = f\"{video_name}_frame_{frame_count}.jpg\" # Nome do frame retirado\n",
    "                    frame_path = output_dir / frame_name\n",
    "                    cv2.imwrite(str(frame_path) , frame)\n",
    "                    imgs.append(frame_path)\n",
    "                    frame_count += 1\n",
    "                count += 1\n",
    "            cap.release()\n",
    "            \n",
    "        # Define um diretorio temporario para guardar os frames extraidos\n",
    "        \n",
    "        extracted_frames_dir = Path(\"extracted_frames\")\n",
    "        extracted_frames_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        for video in videos_files:\n",
    "            extract_frames(video,extracted_frames_dir,frame_rate)\n",
    "    \n",
    "    # 3. Carrega txts\n",
    "    if txts_path:\n",
    "        txts_path = Path(txts_path)\n",
    "        txts = list(txts_path.glob(\"*.txts\"))\n",
    "    else:\n",
    "        txts = []\n",
    "        \n",
    "    # Garantir que haja consistência entre imagens e txts\n",
    "    \n",
    "    img_stems = (img.stem for img in imgs)\n",
    "    txt_stems = (txt.stem for txt in txts)\n",
    "    \n",
    "    # Mantem somente os pares onde imagem e txt existem\n",
    "    \n",
    "    imgs = [img for img in imgs if img.stem in txt_stems]\n",
    "    txts = [txt for txt in txts if txt.stem in img_stems] \n",
    "    \n",
    "    if len(imgs) == 0 or len(txts) == 0:\n",
    "        raise ValueError(\"Nenhum par válido foi encontrado. Cheque o caminho e os formatos\")\n",
    "        \n",
    "    imgs.sort(key=lambda x: x.stem)\n",
    "    txts.sort(key=lambda x: x.stem)\n",
    "    \n",
    "    # 4. Carrega o nome das clases\n",
    "    with open(classes_txt, \"r\") as f:\n",
    "        classes = f.read().splitlines()\n",
    "    \n",
    "    # 5. Preparar as Labels para cada imagem (Usado no Stratificado)\n",
    "    labels = []\n",
    "    for txt in txts:\n",
    "        with open(txt,\"r\") as f:\n",
    "            label_lines = f.readlines()\n",
    "            labels_in_file = [line.split()[0] for line in label_lines]\n",
    "            labels.append(labels_in_file)\n",
    "    \n",
    "    # Comprimir / Achatar as labels em uma listas para contagem\n",
    "    flat_labels = [labels for sublist in labels for label in sublist]\n",
    "    \n",
    "    # 6. Separacao entre Treino e Validação  \n",
    "    imgs_train , imgs_valid , txts_train, txts_valid = train_test_split(\n",
    "        imgs, txts, test_size=val_size , random_state=random_state, stratify=flat_labels\n",
    "        )           \n",
    "    \n",
    "    # 7. Criar a Pasta do Yolo\n",
    "    def create_yolo_dirs(base_path):\n",
    "        labels_dir = base_path/\"labels\"\n",
    "        images_dir = base_path/\"images\"\n",
    "        labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        return labels_dir, images_dir\n",
    "    \n",
    "    # Diretorios para Treino e Validação\n",
    "    \n",
    "    train_labels_dir, train_images_dir = create_yolo_dirs(yolo_ds_path / \"train\")\n",
    "    valid_labels_dir, valid_images_dir = create_yolo_dirs(yolo_ds_path / \"valid\") \n",
    "    \n",
    "    # 8. Copiando as imagens e os labels de treino e testes para os diretorios criados\n",
    "    \n",
    "    def copy_files(imgs,txts,imgs_dst_dir, txt_dst_dir):\n",
    "        for img, txt in zip(imgs,txts):\n",
    "            shutil.copy(img,imgs_dst_dir / img.name)\n",
    "            shutil.copy(txt,txt_dst_dir / txt.name)\n",
    "    \n",
    "    copy_files(imgs_train, txts_train , train_images_dir, train_labels_dir)\n",
    "    copy_files(imgs_valid , txts_valid , valid_images_dir, valid_labels_dir)\n",
    "    \n",
    "    # 9. Criação do YAML para o YOLO\n",
    "\n",
    "    yaml_data = {\n",
    "        \"names\": classes,\n",
    "        \"nc\": len(classes),\n",
    "        \"train\": str(yolo_ds_path / \"train\"),\n",
    "        \"val\": str(yolo_ds_path / \"valid\"),\n",
    "    }\n",
    "    \n",
    "    yaml_path = yolo_ds_path / \"custom_dataset.yaml\"\n",
    "    with open(yaml_path, 'w') as yaml_file:\n",
    "        yaml.dump(yaml_data, yaml_file)\n",
    "        \n",
    "    print(f\"Preprocessing complete. Dataset ready at: {yolo_ds_path}\")\n",
    "    print(f\"YAML file created at: {yaml_path}\")\n",
    "\n",
    "    # Remove o diretorio temporário dos frames\n",
    "    shutil.rmtree(extracted_frames_dir)        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos de Utilização\n",
    "\n",
    "# Preprocessamento de imagens E videos\n",
    "\n",
    "# preprocess_dataset(\n",
    "#     imgs_path=r\"C:\\Users\\isaac\\OneDrive\\Documentos\\Pitayas\\ApenasImagens-20240905T202742Z-001\\ApenasImagens\",\n",
    "#     txts_path=r\"C:\\Users\\isaac\\OneDrive\\Documentos\\Pitayas\\TXTPitaya-20240905T210838Z-001\\TXTPitaya\",\n",
    "#     videos_path=\"path/to/videos\",\n",
    "#     classes_txt=r\"C:\\Users\\isaac\\OneDrive\\Documentos\\Pitayas\\classes.txt\",\n",
    "#     yolo_ds_path=r\"C:\\Users\\isaac\\OneDrive\\Documentos\\Pitayas\\content\\dataset_yolo\",\n",
    "#     val_size=0.2,  # 20% of data for validation\n",
    "#     frame_rate=1   # Extract 1 frame per second from videos\n",
    "# )\n",
    "\n",
    "# Preprocessamento somente de videos\n",
    "\n",
    "# preprocess_dataset(\n",
    "#     videos_path=\"path/to/videos\",\n",
    "#     txts_path=\"path/to/annotations\",\n",
    "#     classes_txt=\"path/to/classes.txt\",\n",
    "#     yolo_ds_path=\"path/to/yolo_dataset\",\n",
    "#     val_size=0.2,  # 20% of data for validation\n",
    "#     frame_rate=2   # Extract 2 frames per second from videos\n",
    "# )\n",
    "\n",
    "# Preprocessamento somente de imagens\n",
    "\n",
    "# preprocess_dataset(\n",
    "#     imgs_path=\"path/to/images\",\n",
    "#     txts_path=\"path/to/annotations\",\n",
    "#     classes_txt=\"path/to/classes.txt\",\n",
    "#     yolo_ds_path=\"path/to/yolo_dataset\",\n",
    "#     val_size=0.2  # 20% of data for validation\n",
    "# )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
